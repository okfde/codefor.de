---
title: "Gedanken zum Smart City Ranking"
author: "Nora Titz(Community Redakteurin)"
date: '2023-11-02T8:00:00+02:00'
excerpt: Kritk am Smart City Ranking von Bitkom
topic: Bitkom
images:
- imgname: header-smart-city.jpg
  attribution: <a href="https://pixabay.com/photos/businessman-tablet-steering-city-3210932/">Foto</a> von <a href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3210932">geralt</a> auf <a href="https://pixabay.com">pixabay.com</a>
og_image: header-smart-city.jpg
type: blog
---

Das „Smart City Ranking“ wird jährlich vom Dachverband der Unternehmer der deutschen IT-Branche, Bitkom, erhoben und umfasst alle deutschen Großstädte. 
Es werden verschiedene Indikatoren in den fünf Kategorien: „Verwaltung“, „IT und Kommunikation“, „Energie und Umwelt“, „Mobilität“ und „Gesellschaft und Bildung“ untersucht. Das Ranking beansprucht den Stand der digitalen Entwicklung von „Stadtgesellschaften“ in einem direkten Vergleich abzubilden. Es ist in erster Linie ein relevantes Feedback für Stadt-Verwaltungen und ihre Arbeit, dabei können nicht alle Faktoren von der Verwaltungen beeinflusst werden bzw. ihr Einfluss auf diese von den Indikatoren des Rankings nicht abgebildet werden.

Als Code for Germany ist unsere Existenz, bzw. die eines OK Labs, ein Faktor für den Indikator „Digitale Szene“ in der Kategorie „Gesellschaft und Bildung“ des Rankings.  
Neben Code for Germany ist hier auch der Chaos Computer Club aufgeführt. Die Auswertung verwundert allerdings und stößt im Fall Ulm besonders bitter auf. 

## Punkte, aber für was?

Das beigefügte Methodenblatt des Rankings ist nicht besonders ausführlich und beschreibt nur beispielhaft wie die Auswertung der einzelnen Indikatoren aussehen könnte. So kritisiert z.B.auch Claus Arndt in der [Rheinischen Post](https://rp-online.de/nrw/staedte/moers/staedte-im-vergleich-moers-schneidet-bei-digitalisierung-schlecht-ab_aid-99429889), dass die Kriterien an vielen Stellen intransparent seien. Für nicht-nummerische Faktoren führt das Methodenblatt das folgende Umrechnungsbeispiel auf:  

Ja, im Einsatz -> 100

In Einführung -> 75

Testphase -> 50

Geplant -> 25

Nein, nicht vorhanden -> 0

Betrachtet man die Zahlen des Indikators „Digitale Szene“ aber einmal genauer wird schnell klar, dass die Punktebewertung hier anders funktioniert, wie genau ist dem Methodenblatt nicht zu entnehmen. Wir nehmen an, dass die Werte wie folgt entstehen: 

Existenz eines... 

CCC Chaostreff -> 40

CCC Erfa-Kreis -> 50 

OK Lab -> 50

Wir weisen darauf hin, dass einige der scheinbar angenommenen OK Labs ruhen, d.h. Es gab mal eine aktive ehrenamtliche Gruppe mit Anbindung an das Code for Germany Netzwerk, diese wird aber gerade nicht mehr mit Leben gefüllt. Dies betrifft die Gruppen und damit die Rankings von: Kiel, Kassel, Paderborn, Potsdam, Mecklenburg-Vorpommern, Jena, Hannover, Osnabrück, Ruhrgebiet (Herne, Recklinghausen, Mühlheim an der Ruhr), Chemnitz, Wuppertal, Düsseldorf, Bonn, Frankfurt, Heidelberg, Stuttgart, Saarbrücken und Essen. Den ruhenden Zustand der Labs kann man seit Juli 2023 auf unserer Website explizit einsehen. 

## Abbildung einer Fassade

Der Anschein, dass hier qualitativ inhaltsleere Zahlen von Websites übernommen werden ohne diese genauer zu untersuchen oder einzuordnen, geht aber über die ruhenden OK Labs hinaus. 

Erstens, sagt die Existenz eines OK Lab erst mal nichts darüber aus, was hier entsteht und wie gut die Zusammenarbeit und der Zugewinn für Stadtgesellschaft, Verwaltung und Ehrenamtlichen tatsächlich sind. So bekommt etwa Ulm die volle Punktzahl im Bereich „Digitale Szene“, obwohl hier auf Grund eines [kräftezehrenden Rechtsstreits](https://netzpolitik.org/2023/hackspace-in-ulm-verschwoerhaus-verliert-seinen-namen-an-die-stadt/) zwischen Stadt und ehrenamtlichen ein Großteil des Jahres kaum inhaltliches passieren und Erwartungen an einen Umgang auf Augenhöhe und die Wertschätzung von ehrenamtlicher Arbeit bitter enttäuscht wurden. 

Zweitens, erscheinen viele weitere Faktoren eher als Abbild einer Fassade denn als guter Leitwert. Was sagt zum Beispiel die Menge der aktuellen Datensätze über die Qualität der Infrastruktur eines Datenportals aus? Hier wird eine Fassade schneller und höher belohnt als der langwierige Aufbau einer funktionalen Infrastruktur. Diese ist aber essentieller Grundbaustein für eine nachhaltige Digitalisierung. 

Insgesamt bleiben beim Smart City Ranking viele Fragen offen. Während an einigen Stellen erfreulicherweise die Nutzungsfreundlichkeit als Indikator herangezogen wird, bleibt unklar wer eigentlich bewertet was Informationsgehalt und Nutzungsfreundlichkeit sind? Wie werden Instagram, Youtube und Twitter als relevanteste Öffentlichkeitskanäle gerechtfertigt? Wer stellt eigentlich zu welchen externen Kosten Sharinganbieter zur Verfügung und sind dies nicht relevante Fragen für eine smarte und nachhaltige Entwicklung von Städten? 

Für den Stand der "Digitalen Szene" in Stadt x, fragt uns doch einfach das nächste mal.  




